id: 262008
key: 0273757e-bd54-42b2-a099-2d9d8c6fb999
locale: en-us
version: 1.0.0
title: Applying Deep Learning
semantic_type: Lesson
updated_at: 'Sun Apr 23 2017 23:43:19 GMT+0000 (UTC)'
is_public: true
image:
  url: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/April/58ed4dc6_09/09.jpg'
  width: 1000
  height: 1000
video: null
summary: 'In this lesson, you''ll get your hands dirty by playing around with a few examples of deep learning. Don''t worry if you don''t understand what''s going on! The goal here is just for you to play around with some models others have already created and have fun.'
duration: 60
is_project_lesson: false
_concepts_ids:
  - 262194
  - 257308
  - 262112
  - 262189
  - 262178
_project_id: null
concepts:
  - id: 262194
    key: 696379df-e52e-4296-883a-cdd17d415e4d
    locale: en-us
    version: 1.0.0
    title: Introduction
    semantic_type: Concept
    updated_at: 'Fri Jan 27 2017 04:50:27 GMT+0000 (UTC)'
    is_public: true
    resources: null
    _atoms_ids:
      - 262195
      - 262196
    atoms:
      - id: 262195
        key: 77d99d05-f9a6-4138-8d78-9cb324df593c
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: ImageAtom
        updated_at: 'Fri Jan 27 2017 15:46:02 GMT+0000 (UTC)'
        is_public: true
        url: 'https://d17h27t6h515a5.cloudfront.net/topher/2016/December/58472d92_mat-headshot/mat-headshot.png'
        width: 250
        height: 250
        caption: 'Hi, It''s Mat again!'
        resources: null
        instructor_notes: null
      - id: 262196
        key: b9393be2-3907-4990-a913-fc45d0e69d73
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Fri Jan 27 2017 20:57:22 GMT+0000 (UTC)'
        is_public: true
        text: |-
          # Introduction

          In this lesson, we're going to go over a few really cool applications of Deep Learning using pre-trained models that others have generously provided on github. Don't worry if you don't understand what's going on! The goal is just for you to see the power of Deep Learning in a few different contexts and play around with these models. You'll get to dive deep into such models later on in the program. For now just have fun and plug in your own examples where possible!

          Note that this lesson is totally optional and that if you want to skip ahead, you should feel free to do so!
        instructor_notes: ''
        resources: null
  - id: 257308
    key: 7991da18-bbd0-4606-83e5-3bc5ce558e70
    locale: en-us
    version: 1.0.0
    title: Style Transfer
    semantic_type: Concept
    updated_at: 'Sat Feb 18 2017 01:40:51 GMT+0000 (UTC)'
    is_public: true
    resources:
      files:
        - name: Rain Princess checkpoint
          uri: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/587d1865_rain-princess/rain-princess.ckpt'
        - name: La Muse checkpoint
          uri: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa800_la-muse/la-muse.ckpt'
        - name: Udnie checkpoint
          uri: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa846_udnie/udnie.ckpt'
        - name: Scream checkpoint
          uri: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa883_scream/scream.ckpt'
        - name: Wave checkpoint
          uri: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa89d_wave/wave.ckpt'
        - name: Wreck checkpoint
          uri: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa8b6_wreck/wreck.ckpt'
      google_plus_link: null
      career_resource_center_link: null
      coaching_appointments_link: null
      office_hours_link: null
    _atoms_ids:
      - 257311
      - 257310
      - 257312
      - 262155
      - 262201
      - 267215
    atoms:
      - id: 257311
        key: e253bd8f-4815-4c99-aab2-9a29126b0124
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Sat Feb 18 2017 01:17:03 GMT+0000 (UTC)'
        is_public: true
        text: |-
          # Style Transfer

          As an example of the kind of things you'll be building with deep learning models, here is a really fun project, [fast style transfer](https://github.com/lengstrom/fast-style-transfer). Style transfer allows you to take famous paintings, and recreate your own images in their styles! The network learns the underlying techniques of those paintings and figures out how to apply them on its own. This model was trained on the styles of famous paintings and is able to transfer those styles to other images and [even videos](https://www.youtube.com/watch?v=xVJwwWQlQ1o)!

          I used it to style my cat Chihiro in the style of [Hokusai](https://en.wikipedia.org/wiki/Hokusai)'s  [*The Great Wave Off Kanagawa*](https://en.wikipedia.org/wiki/The_Great_Wave_off_Kanagawa).
        instructor_notes: ''
        resources: null
      - id: 257310
        key: 872d63ad-51a9-4f1c-8b22-4c17d96779b4
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: ImageAtom
        updated_at: 'Fri Jan 27 2017 23:53:38 GMT+0000 (UTC)'
        is_public: true
        url: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/587d0443_chi-waves/chi-waves.png'
        width: 464
        height: 877
        caption: ''
        resources: null
        instructor_notes: null
      - id: 257312
        key: 2fe49c4c-ecc3-4a68-b12e-cb6feb09aead
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Fri May 26 2017 19:09:25 GMT+0000 (UTC)'
        is_public: true
        text: |
          To try it out yourself, you can find the code in the [fast-style-transfer GitHub repo](https://github.com/lengstrom/fast-style-transfer). Either use `git` to clone the repository, or you can download the whole thing as a Zip archive and extract it.

          The network has been trained on a few different styles ([here](https://github.com/lengstrom/fast-style-transfer/tree/master/examples/style)) and saved into [checkpoint files](https://drive.google.com/drive/folders/0B9jhaT37ydSyRk9UX0wwX3BpMzQ). Checkpoint files contain all the information about the trained network to apply styles to new images.

          ## Dependencies

          The easiest way to install all the packages needed to run this code is with [Miniconda](http://conda.pydata.org/miniconda.html), a smaller version of [Anaconda](https://www.continuum.io/downloads). Miniconda comes with Conda, a package and environment manager built specifically for data science. Install the Python 3 version of Miniconda appropriate for your operating system.

          If you haven't used Conda before, please quickly run through the Anaconda lesson (Lesson 2 on this part).

          ### Windows

          For Windows, you'll need to install TensorFlow 0.12.1, Python 3.5, Pillow 3.4.2, scipy 0.18.1, and numpy 1.11.2.  After installing Miniconda, open your command prompt. In there, enter these commands line by line:

          ```bash
          conda create -n style-transfer python=3.5
          activate style-transfer
          pip install tensorflow
          conda install scipy pillow
          ```

          The first line creates a new environment that will hold the packages needed for the style transfer code. The next line (`activate style-transfer`) enters the environment, you should see the environment name in the prompt at the beginning of the line. The next two install TensorFlow, Scipy, and Pillow (an image processing library).

          ### OS X and Linux 

          For OS X and Linux, you'll need to install TensorFlow 0.11.0, Python 2.7.9, Pillow 3.4.2, scipy 0.18.1, and numpy 1.11.2.  

          In your terminal, enter this commands line by line:

          ```bash
          conda create -n style-transfer python=2.7.9
          source activate style-transfer
          pip install tensorflow
          conda install scipy pillow
          ```

          The first line creates a new environment that will hold the packages needed for the style transfer code. The next line (`source activate style-transfer`) enters the environment, , you should see the environment name in the prompt at the beginning of the line. The next two install TensorFlow, Scipy, and Pillow (an image processing library).
        instructor_notes: ''
        resources: null
      - id: 262155
        key: 446465df-8468-48f8-b177-5a61eaf77465
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Fri Mar 24 2017 05:52:54 GMT+0000 (UTC)'
        is_public: true
        text: |-
          ## Transferring styles

          1. Download the Zip archive from the [fast-style-transfer](https://github.com/lengstrom/fast-style-transfer) repository and extract it. You can download it by clicking on the bright green button on the right.
          2. Download the Rain Princess checkpoint from [here](https://d17h27t6h515a5.cloudfront.net/topher/2017/January/587d1865_rain-princess/rain-princess.ckpt). Put it in the fast-style-transfer folder. A checkpoint file is a model that already has tuned parameters. By using this checkpoint file, we won't need to train the model and can get straight to applying it.
          3. Copy the image you want to style into the fast-style-transfer folder.
          4. Enter the Conda environment you created above, if you aren't still in it.
          5. In your terminal, navigate to the fast-style-transfer folder and enter
          ```bash
          python evaluate.py --checkpoint ./rain-princess.ckpt --in-path <path_to_input_file> --out-path ./output_image.jpg
          ```

          > **Note:** Your checkpoint file might be named `rain_princess.ckpt`, notice the underscore, it's not the dash from above.

          You can get more checkpoint files at the bottom of this page. Try them all!

          Share what you create in the [forums](https://discussions.udacity.com) or on the [Slack](https://nd101.slack.com) channel #l-applying-dl. We'd love to see what you come up with. Also, feel free to train the network on your own images, you can find instructions in the repository (although it does take some powerful hardware).

          > **Note:** Be careful with the size of the input image. The style transfer can take quite a while to run on larger images.
        instructor_notes: ''
        resources: null
      - id: 262201
        key: 58431738-f89a-4d96-8fd4-d279255a21af
        locale: en-us
        version: 1.0.0
        title: Style Transfer Checklist
        semantic_type: TaskListAtom
        updated_at: 'Fri Jan 27 2017 22:57:10 GMT+0000 (UTC)'
        is_public: true
        tasks:
          - Apply style transfer to an image of yourself or something personal to you.
          - 'Share your image on the Udacity [forums](https://discussions.udacity.com) or [Slack team](https://nd101.slack.com) at the channel #l-applying-dl.'
        positive_feedback: Congratulations on using Deep Learning with style transfer!
        video_feedback: null
        description: ''
      - id: 267215
        key: 77fb8970-50c3-49db-a450-a9f6746f8cba
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Sat Feb 18 2017 01:40:51 GMT+0000 (UTC)'
        is_public: true
        text: |-
          The checkpoints were trained on the following paintings:

          * Rain Princesss, by [Leonid Afremov](https://afremov.com/Leonid-Afremov-bio.html)
          * La Muse, by [Pablo Picasso](https://en.wikipedia.org/wiki/Pablo_Picasso)
          * Udnie by [Francis Picabia](https://en.wikipedia.org/wiki/Francis_Picabia)
          * Scream, by [Edvard Munch](https://en.wikipedia.org/wiki/Edvard_Munch)
          * The Great Wave off Kanagawa, by [Hokusai](https://en.wikipedia.org/wiki/Hokusai)
          * The Shipwreck of the Minotaur, by [J.M.W. Turner](https://en.wikipedia.org/wiki/J._M._W._Turner)
        instructor_notes: ''
        resources: null
  - id: 262112
    key: 7e3a8e79-acc0-4f77-8eb2-81513d3d1b0d
    locale: en-us
    version: 1.0.0
    title: DeepTraffic
    semantic_type: Concept
    updated_at: 'Thu Feb 02 2017 16:45:43 GMT+0000 (UTC)'
    is_public: true
    resources: null
    _atoms_ids:
      - 262927
      - 262223
    atoms:
      - id: 262927
        key: a9092750-757a-4947-819c-41b1e8ea04d1
        locale: en-us
        version: 1.0.0
        title: Traffic Navigation 3
        semantic_type: VideoAtom
        updated_at: 'Wed Apr 19 2017 21:38:16 GMT+0000 (UTC)'
        is_public: true
        tags: []
        instructor_notes: ''
        resources: null
        video:
          youtube_id: az5ElmV4DhY
          subtitles: null
          transcodings:
            uri_480p_mp4: 'http://video.udacity-data.com.s3.amazonaws.com/topher/2017/February/58936212_traffic-navigation-3/traffic-navigation-3_480p.mp4'
            uri_480p_1000kbps_mp4: 'http://video.udacity-data.com.s3.amazonaws.com/topher/2017/February/58936212_traffic-navigation-3/traffic-navigation-3_480p_1000kbps.mp4'
            uri_480p_ogg: 'http://video.udacity-data.com.s3.amazonaws.com/topher/2017/February/58936212_traffic-navigation-3/traffic-navigation-3_480p.ogg'
            uri_720p_mp4: 'http://video.udacity-data.com.s3.amazonaws.com/topher/2017/February/58936212_traffic-navigation-3/traffic-navigation-3_720p.mp4'
            uri_hls: 'http://video.udacity-data.com.s3.amazonaws.com/topher/2017/February/58936212_traffic-navigation-3/hls/playlist.m3u8'
      - id: 262223
        key: 4fbe69d6-16ea-44a5-811e-054863e13a3e
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Sun Jan 29 2017 19:34:53 GMT+0000 (UTC)'
        is_public: true
        text: |-
          ## DeepTraffic

          You can find the DeepTraffic simulator [here](http://selfdrivingcars.mit.edu/deeptrafficjs/). The network here is attempting to learn a driving strategy such that the car is moving as fast as possible using [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning). The network is rewarded when the car chooses actions that result in it moving fast. It's this feedback that allows the network to find a strategy of actions for optimal speed.

          To learn more about setting the parameters and training the network, read the [overview here](http://selfdrivingcars.mit.edu/deeptraffic/).

          Discuss how you built your network and your results with your fellow students in the #deeptraffic channel on Slack.
        instructor_notes: ''
        resources: null
  - id: 262189
    key: 88972d8b-e8a9-4789-ae79-6077db50dad9
    locale: en-us
    version: 1.0.0
    title: Flappy Bird
    semantic_type: Concept
    updated_at: 'Fri Jan 27 2017 04:34:53 GMT+0000 (UTC)'
    is_public: true
    resources: null
    _atoms_ids:
      - 262190
      - 262191
      - 262192
    atoms:
      - id: 262190
        key: 48a62f68-4b20-43af-ac08-463d107cff31
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Fri Jan 27 2017 04:55:54 GMT+0000 (UTC)'
        is_public: true
        text: |-
          ### Flappy Bird

          In this example, you'll get to see a Deep Learning agent playing Flappy Bird! You have the option to train the agent yourself, but for now let's just start with the pre-trained network given by the author. Note that the following agent is able to play without being told any information about the structure of the game or its rules. It automatically discovers the rules of the game by finding out how it did on each iteration.

          We will be following [this repository](https://github.com/yenchenlin/DeepLearningFlappyBird) by Yenchen Lin.
        instructor_notes: ''
        resources: null
      - id: 262191
        key: 09e36dde-02ab-4a25-bd2d-f7d2f0334ab7
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: ImageAtom
        updated_at: 'Fri Jan 27 2017 04:28:21 GMT+0000 (UTC)'
        is_public: true
        url: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588acc5c_flappy-bird/flappy-bird.jpg'
        width: 810
        height: 456
        caption: ''
        resources: null
        instructor_notes: null
      - id: 262192
        key: f76787f6-a04e-4bda-8ac8-0141da018c6f
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Mon Jan 30 2017 23:51:46 GMT+0000 (UTC)'
        is_public: true
        text: |-
          ### Instructions

          1. Install miniconda or anaconda if you have not already. You can follow [our tutorial](https://classroom.udacity.com/nanodegrees/nd101/parts/2a9dba0b-28eb-4b0e-acfa-bdcf35680d90/modules/329a736b-1700-43d4-9bf0-753cc461bebc/lessons/9e9ed61d-20c3-4431-95aa-a1099f28d601/concepts/4cdc5a26-1e54-4a69-8eb4-f15e37aaab7b) for help.
          2. Create an environment for flappybird
              * Mac/Linux: `conda create --name=flappybird python=2.7`
              * Windows: `conda create --name=flappybird python=3.5`
          3. Enter your conda environment
              * Mac/Linux: `source activate flappybird`
              * Windows: `activate flappybird`
          4. `conda install -c menpo opencv3`
          5. `pip install pygame`
          6. `pip install tensorflow`
          7. `git clone https://github.com/yenchenlin/DeepLearningFlappyBird.git`
          8. `cd DeepLearningFlappyBird`
          9. `python deep_q_network.py`

          If all went correctly, you should be seeing a Deep Learning based agent play Flappy Bird! The repository contains instructions for training your own agent if you're interested!
        instructor_notes: ''
        resources: null
  - id: 262178
    key: eb539882-9057-4c4f-ad33-5eb23837474f
    locale: en-us
    version: 1.0.0
    title: Books to read
    semantic_type: Concept
    updated_at: 'Fri Jan 27 2017 04:37:21 GMT+0000 (UTC)'
    is_public: true
    resources: null
    _atoms_ids:
      - 262187
      - 262179
    atoms:
      - id: 262187
        key: 0ed5414f-17b9-4118-a74b-4fc8b4cc15b9
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: ImageAtom
        updated_at: 'Fri Jan 27 2017 04:19:42 GMT+0000 (UTC)'
        is_public: true
        url: 'https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aca59_grokking-deep-learning/grokking-deep-learning.jpg'
        width: 399
        height: 499
        caption: ''
        resources: null
        instructor_notes: null
      - id: 262179
        key: 79893164-9704-4714-80b2-d27e91865db4
        locale: en-us
        version: 1.0.0
        title: null
        semantic_type: TextAtom
        updated_at: 'Fri Jan 27 2017 21:08:30 GMT+0000 (UTC)'
        is_public: true
        text: |-
          # Books to read

          We believe that you learn best when you are exposed to multiple perspectives on the same idea. As such, we recommend checking out a few of the books below to get an added perspective on Deep Learning.

          * [Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) by Andrew Trask. Use our exclusive discount code **traskud17** for 40% off. This provides a very gentle introduction to Deep Learning and covers the intuition more than the theory.


          * [Neural Networks And Deep Learning](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen. This book is more rigorous than Grokking Deep Learning and includes a lot of fun, interactive visualizations to play with.


          * [The Deep Learning Textbook](http://www.deeplearningbook.org/) from Ian Goodfellow, Yoshua Bengio, and Aaron Courville. This online book has lot of material and is the most rigorous of the three books suggested.
        instructor_notes: ''
        resources: null
